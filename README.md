<h1 align="center">ğŸ§  Neurodegenerative Disease Detection using CNN</h1>

<p align="center">
  <b>ğŸ“ Undergraduate Thesis Project (Completed)</b><br>
  <i>Detection of Alzheimerâ€™s, Parkinsonâ€™s & FTD from MRI using Deep Learning</i><br><br>
  <img src="https://img.shields.io/badge/Status-Completed-brightgreen?style=flat-square">
  <img src="https://img.shields.io/badge/Data-ADNI,PPMI,FTD-orange?style=flat-square">
  <img src="https://img.shields.io/badge/Model-SadNetV1-green?style=flat-square">
</p>

---

## ğŸš€ Overview

This research focuses on the early diagnosis of **Alzheimerâ€™s**, **Parkinsonâ€™s**, and **Frontotemporal Dementia (FTD)** using **2D sagittal MRI slices** with a **pseudo-3D deep learning pipeline**.

Our custom model, **SadNetV1**, builds on **MobileNetV2** and enhances feature learning with **Squeeze-and-Excitation (SE) attention blocks** for high-performance, lightweight disease classification.

> ğŸ§¾ Status: Successfully submitted and defended at **BRAC University, Dept. of CSE**  
> ğŸ” Code & datasets are private due to ethical and academic regulations

---

## ğŸ“š Datasets Used

- **ADNI** â€“ Alzheimerâ€™s MRI data  
- **PPMI** â€“ Parkinsonâ€™s data  
- **FTD** â€“ Neuroimaging data for Frontotemporal Dementia  

**Preprocessing includes:**
- ğŸšï¸ Intensity clipping (0â€“255)
- ğŸ¨ Conditional CLAHE
- ğŸ“ Resizing (224Ã—224)
- ğŸ§¼ Normalization
- ğŸ§¾ Saved as `.png` format

### ğŸ§ª Sample MRI Slice
<img width="395" alt="Sample Slice" src="https://github.com/user-attachments/assets/99c39dec-581a-4882-bfbf-8ff2e7b9097a" />

---

## ğŸ”„ Data Preprocessing Pipeline

<img width="438" alt="Preprocessing Flowchart" src="https://github.com/user-attachments/assets/374aa9c8-e204-496d-a6cb-b1b95e3cef39" />

---

## ğŸ“ˆ Data Augmentation Process

- ğŸ”€ Dataset split into Train, Validation, Test sets
- ğŸ”„ Applied rotation, zoom, flips, contrast shifts

### ğŸ“Š Split Summary
<img src="https://github.com/user-attachments/assets/d1160f6f-b775-4f2d-9283-992b45e8ef7f" style="width:50%; height:auto;" />

### ğŸ§ª Augmentation Pipeline
<img src="https://github.com/user-attachments/assets/9e7cef07-9eaa-4517-abcc-d84917fe8b81" width="70%"/>

---

## ğŸ”§ Model Workflow Diagram

<img src="https://github.com/user-attachments/assets/31602497-0db4-4f0f-9d06-38f9df7dfa15" width="75%" />

---

## ğŸ§  Model Architecture â€“ SadNetV1

- ğŸ§© **Base**: MobileNetV2  
- ğŸ” **Attention**: Squeeze-and-Excitation (SE) Blocks  
- ğŸ¯ **Input**: Stacked 2D sagittal MRI (Pseudo-3D)  
- âš™ï¸ **Optimizer**: Adam (`lr=1e-5`)  
- ğŸ“‰ **Loss**: Categorical Crossentropy  

```mermaid
graph LR
A[Input MRI Slice] --> B[Preprocessing]
B --> C[MobileNetV2 + SE]
C --> D[Classification Head]
D --> E[Predicted Disease]
```

---

## ğŸ“Š Performance Summary

SadNetV1 achieved strong results across all diseases:

- âœ… **Train Accuracy**: 96.84%  
- âœ… **Validation Accuracy**: 97.11%  
- âœ… **Test Accuracy**: 96.15%

---

## ğŸ“ˆ Results & Visualizations

<table>
  <tr>
    <td align="center"><b>ğŸ“Š Accuracy Graph</b></td>
    <td align="center"><b>ğŸ“‰ Loss Graph</b></td>
  </tr>
  <tr>
    <td><img width="100%" src="https://github.com/user-attachments/assets/3549ab69-192d-40a6-ad66-80da3b83bb07" /></td>
    <td><img width="100%" src="https://github.com/user-attachments/assets/dcf23989-f534-4ef9-9bc7-8474860c57e1" /></td>
  </tr>
</table>

---

## ğŸ§  Prediction Results

<table>
  <tr>
    <td align="center"><b>Predicted: Alzheimerâ€™s Disease (AD)</b></td>
    <td align="center"><b>Predicted: Parkinsonâ€™s Disease (PD)</b></td>
    <td align="center"><b>Predicted: Frontotemporal Dementia (FTD)</b></td>
  </tr>
  <tr>
    <td><img width="100%" src="https://github.com/user-attachments/assets/078dd72b-b226-4ba0-84e9-950e293652ba" /></td>
    <td><img width="100%" src="https://github.com/user-attachments/assets/d62e0406-77ab-4f43-970e-3f9585466056" /></td>
    <td><img width="100%" src="https://github.com/user-attachments/assets/f9b63741-7837-4679-ba9d-434bb281e9d4" /></td>
  </tr>
</table>

---

## ğŸŒ Future Work

- ğŸŒ Deploy as an interactive web app
- ğŸ§¬ Integrate multi-modal inputs (MRI + PET)
- ğŸ§  Add attention explainability with SHAP & Grad-CAM++

---

## ğŸ› ï¸ Tech Stack

- ğŸ’» Python
- ğŸ”¬ PyTorch
- ğŸ–¼ OpenCV
- ğŸ“Š NumPy, Pandas
- ğŸ“ˆ Matplotlib, Seaborn
- ğŸ§  NiBabel, pydicom
- ğŸ§ª Jupyter Notebook

---

## ğŸ“ Author & Contact

**ğŸ‘¨â€ğŸ’» Shadman Rahman Sameen**  
ğŸ“ Undergraduate Student, Dept. of CSE  
ğŸ« BRAC University, Dhaka, Bangladesh  
ğŸ“§ [shadman.rahman.sameen@g.bracu.ac.bd](mailto:shadman.rahman.sameen@g.bracu.ac.bd)  
ğŸ”— GitHub: [github.com/ShadmanRahman786](https://github.com/ShadmanRahman786)

---

<p align="center"><i>â€œTurning pixels into predictions, one scan at a time.â€</i></p>
